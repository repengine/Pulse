# Module Analysis: `simulation_engine/simulation_drift_detector.py`

## 1. Module Intent/Purpose

The primary role of the [`simulation_engine/simulation_drift_detector.py`](../../simulation_engine/simulation_drift_detector.py) module is to compare two simulation runs by analyzing their trace logs. These logs are expected to be in JSON Lines (`.jsonl`) format. The module aims to detect "drift" between these simulations, which can help identify system instability, unexpected behavioral changes, or silent logic regressions. It achieves this by comparing:
- Rule activation patterns (frequency of each rule firing).
- Overlay decay trajectories (changes in specified emotional or state overlays like "hope", "despair" over time).
- Structural characteristics of the simulation (e.g., total number of turns, occurrence of collapse events).

The output is a JSON report summarizing these differences.

## 2. Operational Status/Completeness

The module appears to be functionally complete for its defined scope.
- It successfully loads and parses trace files.
- It implements comparisons for rule patterns, overlay trajectories, and simulation structure.
- It provides a main function ([`run_simulation_drift_analysis`](../../simulation_engine/simulation_drift_detector.py:83)) to orchestrate the analysis.
- It includes a Command Line Interface (CLI) for ease of use.
- A basic internal test function ([`_test_drift_detector`](../../simulation_engine/simulation_drift_detector.py:132)) exists for manual validation, though it's not run by default when the script is executed.
- There are no explicit `TODO` comments or obvious placeholders in the core logic that would indicate incompleteness for its current functionality.

## 3. Implementation Gaps / Unfinished Next Steps

- **Testing:** The existing test function ([`_test_drift_detector`](../../simulation_engine/simulation_drift_detector.py:132)) is rudimentary and intended for manual validation. A more robust, automated test suite (e.g., using `pytest` or `unittest`) is needed, covering various scenarios, edge cases, and malformed inputs. The use of `tempfile.mktemp` in the test is also a minor security/warning concern.
- **Advanced Drift Detection:** Overlay comparison currently uses average absolute difference. More sophisticated statistical methods or distribution comparison techniques could provide deeper insights into drift.
- **Error Handling:** While some error handling exists (e.g., skipping malformed JSON lines in [`load_trace`](../../simulation_engine/simulation_drift_detector.py:22)), it primarily prints to the console. A more structured error reporting or custom exception system could be beneficial.
- **Configuration & Extensibility:**
    - The schema of the trace files (expected keys like `"fired_rules"`, `"overlays"`) is implicit. Formalizing this with schemas (e.g., Pydantic models) could improve robustness.
    - The module could be extended to support different trace formats or comparison strategies through a plugin architecture.
- **Integration:** The module is standalone. Future work could involve integrating it into a CI/CD pipeline for automated regression testing or a broader simulation monitoring framework.
- **Historical Drift Analysis:** Currently compares two specific traces. It could be enhanced to track drift over a sequence of simulation runs or against a stable baseline.

## 4. Connections & Dependencies

-   **Direct Imports from Other Project Modules:** None. This module appears to be a self-contained utility.
-   **External Library Dependencies:**
    *   [`json`](https://docs.python.org/3/library/json.html) (Python standard library): For parsing JSONL trace files and formatting output.
    *   [`typing`](https://docs.python.org/3/library/typing.html) (Python standard library): For type hints.
    *   [`collections.Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) (Python standard library): Used in [`compare_rule_patterns`](../../simulation_engine/simulation_drift_detector.py:38) to count rule occurrences.
    *   [`os`](https://docs.python.org/3/library/os.html) (Python standard library): Potentially used by `tempfile`, though not directly in the main logic.
    *   [`argparse`](https://docs.python.org/3/library/argparse.html) (Python standard library): For parsing CLI arguments.
-   **Interaction with Other Modules via Shared Data:**
    *   Consumes `.jsonl` trace files which are presumably generated by other components of the `simulation_engine`. It does not directly call other Python modules within the project.
-   **Input/Output Files:**
    *   **Input:** Two simulation trace files in JSON Lines (`.jsonl`) format. Paths are provided as arguments.
    *   **Output:** A JSON formatted report detailing the detected drift. This report is printed to standard output and can optionally be saved to a specified file via a CLI argument.

## 5. Function and Class Example Usages

The module primarily consists of functions. Key functions include:

-   **[`load_trace(path: str) -> List[Dict]`](../../simulation_engine/simulation_drift_detector.py:22):**
    *   Loads and parses a `.jsonl` trace file.
    *   *Usage:* `trace_data = load_trace("path/to/simulation_run.jsonl")`

-   **[`compare_rule_patterns(prev: List[Dict], curr: List[Dict]) -> Dict[str, int]`](../../simulation_engine/simulation_drift_detector.py:38):**
    *   Compares rule activation frequencies between two traces.
    *   *Usage:* `rule_differences = compare_rule_patterns(previous_trace_data, current_trace_data)`

-   **[`compare_overlay_trajectories(prev: List[Dict], curr: List[Dict], keys: Optional[List[str]] = None) -> Dict[str, float]`](../../simulation_engine/simulation_drift_detector.py:54):**
    *   Compares the average difference in specified overlay values.
    *   *Usage:* `overlay_drift_metrics = compare_overlay_trajectories(prev_trace, curr_trace, keys=["hope", "trust"])`

-   **[`compare_simulation_structure(prev: List[Dict], curr: List[Dict]) -> Dict`](../../simulation_engine/simulation_drift_detector.py:73):**
    *   Compares structural aspects like turn counts.
    *   *Usage:* `structural_comparison = compare_simulation_structure(prev_trace, curr_trace)`

-   **[`run_simulation_drift_analysis(prev_path: str, curr_path: str, overlay_keys: Optional[List[str]] = None) -> Dict`](../../simulation_engine/simulation_drift_detector.py:83):**
    *   Orchestrates the full drift analysis process.
    *   *Usage:* `report = run_simulation_drift_analysis("run1.jsonl", "run2.jsonl")`

-   **CLI Usage:**
    ```bash
    python simulation_engine/simulation_drift_detector.py \
      --prev path/to/previous_trace.jsonl \
      --curr path/to/current_trace.jsonl \
      --export path/to/drift_report.json \
      --overlays hope,despair,trust
    ```

## 6. Hardcoding Issues

-   **Default Overlay Keys:** In [`compare_overlay_trajectories`](../../simulation_engine/simulation_drift_detector.py:59), a default list of overlay keys (`["hope", "despair", "rage", "fatigue", "trust"]`) is used if none are provided. While this is configurable, it represents a set of default assumptions.
-   **Default Overlay Value Imputation:** In the nested [`get_overlay_series`](../../simulation_engine/simulation_drift_detector.py:57) function within `compare_overlay_trajectories`, if an overlay key is missing for a given step in the trace, it defaults to `0.5`. This "magic number" is an imputation strategy that might not be universally appropriate.
-   **Trace File Structure:** The module implicitly expects specific keys within the JSON objects of the trace files (e.g., `"fired_rules"`, `"overlays"`, `"collapse"`). This is less a hardcoding issue and more a dependency on a specific data schema.

## 7. Coupling Points

-   **Trace File Format:** The module is tightly coupled to the structure and format of the `.jsonl` simulation trace files. Changes to this format (e.g., key names, data types) generated by other parts of the simulation engine would necessitate modifications in this detector.
-   **CLI Arguments:** The script's functionality when run directly is coupled to its defined CLI arguments (`--prev`, `--curr`, `--export`, `--overlays`).

## 8. Existing Tests

-   A single, basic test function, [`_test_drift_detector()`](../../simulation_engine/simulation_drift_detector.py:132), is present within the module.
-   **Nature:** This function is designed for manual validation. It creates small, dummy trace datasets in memory, writes them to temporary files using `tempfile.mktemp()`, runs the main analysis function, and prints the result.
-   **Coverage:** Coverage is minimal, testing only a very simple, controlled scenario. It does not cover edge cases, error conditions (e.g., file not found, malformed trace files beyond single lines), or different configurations of overlay keys.
-   **Framework:** It does not use a formal testing framework like `pytest` or `unittest`.
-   **Gaps:**
    *   No automated test suite.
    *   No tests for the CLI argument parsing and handling.
    *   No tests for robustness against various malformed inputs or empty files.
    *   The use of `tempfile.mktemp()` is generally discouraged due to potential security vulnerabilities; safer alternatives like `tempfile.NamedTemporaryFile` or `tempfile.TemporaryDirectory` are preferred.
-   There is no indication of a corresponding test file (e.g., `tests/test_simulation_drift_detector.py`) in the project structure provided.

## 9. Module Architecture and Flow

1.  **Initialization & Input:** The module can be invoked programmatically by calling [`run_simulation_drift_analysis()`](../../simulation_engine/simulation_drift_detector.py:83) or via the CLI. It requires paths to two simulation trace files (`previous` and `current`).
2.  **Trace Loading ([`load_trace`](../../simulation_engine/simulation_drift_detector.py:22)):** Each trace file (JSONL format) is read line by line. Each line is parsed as a JSON object. Malformed lines are skipped with a warning. If loading fails critically, an empty list is returned.
3.  **Comparative Analysis:**
    *   **Rule Patterns ([`compare_rule_patterns`](../../simulation_engine/simulation_drift_detector.py:38)):** Counts the occurrences of each `fired_rules` ID in both traces and calculates the delta (current - previous).
    *   **Overlay Trajectories ([`compare_overlay_trajectories`](../../simulation_engine/simulation_drift_detector.py:54)):** For a list of specified (or default) overlay keys, it extracts the time series of their values from both traces. It then calculates the average absolute difference between these series up to the length of the shorter series.
    *   **Simulation Structure ([`compare_simulation_structure`](../../simulation_engine/simulation_drift_detector.py:73)):** Compares high-level metrics: total turn counts for each trace, the difference in turn counts, and whether a "collapse" event was triggered in each trace.
4.  **Aggregation & Reporting ([`run_simulation_drift_analysis`](../../simulation_engine/simulation_drift_detector.py:83)):** This function orchestrates the calls to the loading and comparison functions. It aggregates all results into a structured dictionary, which also includes metadata about the analysis (source file, input paths).
5.  **Output:**
    *   If called programmatically, the dictionary report is returned.
    *   If run via CLI, this dictionary is printed to `stdout` as a formatted JSON string. Optionally, it can be saved to a specified output file.

## 10. Naming Conventions

-   **Functions and Variables:** Generally adhere to PEP 8 standards, using `snake_case` (e.g., [`load_trace`](../../simulation_engine/simulation_drift_detector.py:22), `rule_delta`).
-   **Type Hinting:** The module makes good use of Python type hints, enhancing readability and maintainability.
-   **Internal Functions:** The test function [`_test_drift_detector`](../../simulation_engine/simulation_drift_detector.py:132) uses a leading underscore, conventionally indicating it's for internal use.
-   **Clarity:** Names are generally descriptive and understandable (e.g., `prev_path`, `curr_counts`, `overlay_drift`).
-   **Module Docstring:** The module includes a docstring explaining its purpose, author ("Pulse AI Engine"), and version ("v1.0.0"). The author and version might be placeholders or AI-generated attributions.
-   **Consistency:** Naming is consistent throughout the module. No significant deviations from common Python conventions or potential AI assumption errors in naming were observed.